# 深度学习入门

## 感知机

感知机是由美国学者Frank Rosenblatt在1957年提出来的。为何我们现在还要学习这一很久以前就有的算法呢？因为感知机也是作为神经网络（深度学习）的起源的算法。因此，学习感知机的构造也就是学习通向神经网络和深度学习的一种重要思想。

### 感知机是什么

感知机接收多个输入信号，输出一个信号。

感知机的多个输入信号都有各自固有的权重，这些权重发挥着控制各个信号的重要性的作用。也就是说，权重越大，对应该权重的信号的重要性就越高。

![image-20201212233444998](../Bolg/图片/深度学习/image-20201212233444998.png)

感知机的运行原理只有这些！把上述内容用数学式来表示，就是式

![image-20201212233510310](../Bolg/图片/深度学习/image-20201212233510310.png)

### 简单逻辑电路

#### 与门

与门是有两个输入和一个输出的门电路。

与门仅在两个输入均为1时输出1，其他时候则输出0。

![image-20201212233607196](../Bolg/图片/深度学习/image-20201212233607196.png)

用感知机来表示这个与门

实际上，满足条件的参数的选择方法有无数多个。比如，当(ω1, ω2, θ) = (0.5, 0.5, 0.7) 时，可以满足。此外，当 (ω1, ω2, θ)为(0.5, 0.5, 0.8)或者(1.0, 1.0, 1.0)时，同样也满足与门的条件。设定这样的参数后，仅当x1和x2同时为1时，信号的加权总和才会超过给定的阈值θ。

#### 与非门

与非门（NAND gate）。NAND是Not AND的意思，与非门就是颠倒了与门的输出。用真值表表示的话，如图所示

![image-20201212233950251](../Bolg/图片/深度学习/image-20201212233950251.png)

仅当x1和x2同时为1时输出0，其他时候则输出1。

要表示与非门，可以用 (w1, w2, θ) = (−0.5, −0.5, −0.7) 这样的组合（其他的组合也是无限存在的）。实际上，只要把实现与门的参数值的符号取反，就可以实现与非门。

#### 或门

或门是“只要有一个输入信号是1，输出就为1”的逻辑电路。

![image-20201212234105374](../Bolg/图片/深度学习/image-20201212234105374.png)

### 感知机的实现

#### 简单的实现

用Python来实现刚才的逻辑电路。这里，先定义一个接收参数 x1和 x2的 AND函数。

```python
def AND(x1, x2):
    w1, w2, theta = 0.5, 0.5, 0.7
    tmp = x1*w1 + x2*w2
    if tmp <= theta:
        return 0
    elif tmp > theta:
        return 1
```

在函数内初始化参数 w1、w2、theta，当输入的加权总和超过阈值时返回 1，否则返回 0。

